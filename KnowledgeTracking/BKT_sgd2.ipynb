{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "import sys\n",
    "import datetime\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/local-scratch/localhome/pagand/projects/mygitsDaTu/AITutor_SeqModeling/KnowledgeTracking\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "# it should end with this: /AITutor_SeqModeling\n",
    "# if not, run the next block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/local-scratch/localhome/pagand/projects/mygitsDaTu/AITutor_SeqModeling\n"
     ]
    }
   ],
   "source": [
    "# run if the current directory is not AITutor_SeqModeling\n",
    "cwd = os.chdir(os.path.join(os.getcwd(), \"..\"))\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download the groups as a set\n",
    "a = pd.read_csv(\"data/Groups.csv\")\n",
    "valid_ids = set(a[\"id\"].values)\n",
    "len(valid_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>skill</th>\n",
       "      <th>correct</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1</td>\n",
       "      <td>[Supervised Learning, Classification Algorithms]</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a1</td>\n",
       "      <td>[Supervised Learning, Classification Algorithms]</td>\n",
       "      <td>False</td>\n",
       "      <td>3.726700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a2</td>\n",
       "      <td>[Supervised Learning, Classification Algorithms]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a2</td>\n",
       "      <td>[Supervised Learning, Classification Algorithms]</td>\n",
       "      <td>True</td>\n",
       "      <td>1.987467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a3</td>\n",
       "      <td>[Supervised Learning, Classification Algorithms]</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  username                                             skill  correct  \\\n",
       "0       a1  [Supervised Learning, Classification Algorithms]     True   \n",
       "1       a1  [Supervised Learning, Classification Algorithms]    False   \n",
       "2       a2  [Supervised Learning, Classification Algorithms]    False   \n",
       "3       a2  [Supervised Learning, Classification Algorithms]     True   \n",
       "4       a3  [Supervised Learning, Classification Algorithms]     True   \n",
       "\n",
       "       time  \n",
       "0  0.000000  \n",
       "1  3.726700  \n",
       "2  0.000000  \n",
       "3  1.987467  \n",
       "4  0.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "File_pickle = \"data/KT_logs_annotated.pkl\"\n",
    "\n",
    "# read from pickle\n",
    "df = pd.read_pickle(File_pickle)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the number of unique usernames\n",
    "len(df[\"username\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get rid of entries where username is not in the valid_ids\n",
    "df = df[df[\"username\"].isin(valid_ids)]\n",
    "len(df[\"username\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = pickle.load(open(\"data/Skill_hirereachy.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 1: Only user params\n",
    "# user_params = {}\n",
    "\n",
    "# def initialize_user_params(user_id, skills):\n",
    "#     user_params[user_id] = {}\n",
    "#     for skill in skills.keys():\n",
    "#         skill_params = skills[skill][-1]\n",
    "#         user_params[user_id][skill] = {\n",
    "#             \"P(L)\": skill_params[0],\n",
    "#             \"P(T)\": skill_params[1],\n",
    "#             \"P(G)\": skill_params[2],\n",
    "#             \"P(S)\": skill_params[3]\n",
    "#         }\n",
    "# for user_id in df[\"username\"].unique():\n",
    "#     initialize_user_params(user_id, skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 2: seperate user-specific and skill specific parameters\n",
    "def initialize_params(skills, user_ids):\n",
    "    user_params = {}\n",
    "    skill_params = {}\n",
    "    for skill in skills.keys():\n",
    "        skill_params[skill] = {\n",
    "                \"P(L)\": skills[skill][-1][0],\n",
    "                \"P(T)\": skills[skill][-1][1],\n",
    "                \"P(G)\": skills[skill][-1][1],\n",
    "                \"P(S)\": skills[skill][-1][3]\n",
    "            }\n",
    "        for user_id in user_ids:\n",
    "            # assume all users have the same initial skill level\n",
    "            # add prior knowledge here if exists\n",
    "            user_params[user_id] = skill_params.copy()\n",
    "            user_params[user_id]['weight'] = 0.5\n",
    "    return skill_params, user_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill_params, user_params = initialize_params(skills,  df[\"username\"].unique())\n",
    "user_params['a1'][\"weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute P(C_t|L_t, G, S)\n",
    "def compute_prob_correctness(P_L, P_G, P_S, P_T, correct):\n",
    "    if correct:\n",
    "        P_L_obs = P_L* (1 - P_S) /((1 - P_S) * P_L + P_G * (1 - P_L))\n",
    "    else:\n",
    "        P_L_obs = P_L* (P_S) /(P_S * P_L + (1 - P_G) * (1 - P_L))\n",
    "    \n",
    "    P_L_new = P_L_obs + (1 - P_L_obs) * P_T\n",
    "    P_C = P_L_new * (1 - P_S) + (1 - P_L_new) * P_G\n",
    "\n",
    "    # debug\n",
    "    if not (0 <= P_C <= 1):\n",
    "        print(f\"Invalid P(C): {P_C}, P_L: {P_L}, P_G: {P_G}, P_S: {P_S}, P_T: {P_T}\")\n",
    "    return P_C, P_L_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (log-likelihood function)\n",
    "def log_likelihood(interaction_log,  skill_params, user_params):\n",
    "    log_likelihood = 0\n",
    "    expectations = []\n",
    "    for _, row in interaction_log.iterrows():\n",
    "        user_id = row[\"username\"]\n",
    "        skill_list = row[\"skill\"]\n",
    "        correctness = row[\"correct\"]\n",
    "\n",
    "        for skill in skill_list:\n",
    "            # Retrieve user and skill parameters\n",
    "            P_L_user = user_params[user_id][skill][\"P(L)\"]\n",
    "            P_G_user = user_params[user_id][skill][\"P(G)\"]\n",
    "            P_S_user = user_params[user_id][skill][\"P(S)\"]\n",
    "            P_T_user = user_params[user_id][skill][\"P(T)\"]\n",
    "            P_user = [P_L_user, P_G_user, P_S_user, P_T_user]\n",
    "\n",
    "            P_L_skill = skill_params[skill][\"P(L)\"]\n",
    "            P_G_skill = skill_params[skill][\"P(G)\"]\n",
    "            P_S_skill = skill_params[skill][\"P(S)\"]\n",
    "            P_T_skill = skill_params[skill][\"P(T)\"]\n",
    "            P_skill = [P_L_skill, P_G_skill, P_S_skill, P_T_skill]\n",
    "            \n",
    "            weight = user_params[user_id]['weight']\n",
    "\n",
    "            # Weighted average for P(L)\n",
    "            P_L = weight * P_L_user + (1-weight) * P_L_skill\n",
    "            P_G = weight * P_G_user + (1-weight) * P_G_skill\n",
    "            P_S = weight * P_S_user + (1-weight) * P_S_skill\n",
    "            P_T = weight * P_T_user + (1-weight) * P_T_skill\n",
    "\n",
    "            # Compute likelihood\n",
    "            prob, _ = compute_prob_correctness(P_L, P_G, P_S, P_T, correctness)\n",
    "            log_likelihood += np.log(prob + 1e-9)\n",
    "            expectations.append((user_id, skill, prob, correctness, P_user, P_skill))\n",
    "\n",
    "    return -log_likelihood, expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E-Step: Calculate expected probabilities\n",
    "def expectation_step(interaction_log, skill_params, user_params):\n",
    "    skill_grads = defaultdict(lambda: {\"P(L)\": 0, \"P(T)\": 0, \"P(G)\": 0, \"P(S)\": 0})\n",
    "    user_grads = defaultdict(lambda: defaultdict(lambda: {\"P(L)\": 0, \"P(T)\": 0, \"P(G)\": 0, \"P(S)\": 0}))\n",
    "    weight_grads = {user_id: 0 for user_id in user_params.keys()}\n",
    "    loss = 0\n",
    "    likelihood, expectations = log_likelihood(interaction_log,  skill_params, user_params)\n",
    "    if np.isnan(likelihood):\n",
    "        print(\"Log-likelihood NaN detected! Check parameter updates.\")\n",
    "\n",
    "    for user_id, skill, prob, correctness, P_user, P_skill in expectations:\n",
    "        grad = (correctness - prob) / (prob + 1e-9)\n",
    "        loss += (correctness - prob) ** 2\n",
    "\n",
    "        # make each value in user_grads[user_id][skill] 0.5 of its original value\n",
    "\n",
    "        # Update user-specific gradients\n",
    "        w = user_params[user_id]['weight']\n",
    "        user_grads[user_id][skill][\"P(L)\"] = 0.5*(user_grads[user_id][skill][\"P(L)\"]  +\n",
    "                                            grad * w * ((1 - P_user[2])- P_user[1]))\n",
    "        user_grads[user_id][skill][\"P(G)\"] += 0.5*(user_grads[user_id][skill][\"P(G)\"] +\n",
    "                                            grad * w *(1 - P_user[0]))\n",
    "        user_grads[user_id][skill][\"P(S)\"] += 0.5*(user_grads[user_id][skill][\"P(S)\"] +\n",
    "                                            grad* w *(-P_user[0]))\n",
    "        user_grads[user_id][skill][\"P(T)\"] += 0.5*(user_grads[user_id][skill][\"P(T)\"] +\n",
    "                                            grad* w * (1 - P_user[0])*((1 - P_user[2])- P_user[1]))\n",
    "\n",
    "        weight_grads[user_id] = 0.5*(weight_grads[user_id]+ grad)\n",
    "\n",
    "        # Update skill-specific gradients (aggregated across users)\n",
    "        w = -w +1\n",
    "        skill_grads[skill][\"P(L)\"] = 0.5*(skill_grads[skill][\"P(L)\"]+ grad * w * ((1 - P_skill[2])- P_skill[1]))\n",
    "        skill_grads[skill][\"P(G)\"] = 0.5*(skill_grads[skill][\"P(G)\"]+ grad * w *(1 - P_skill[0]))\n",
    "        skill_grads[skill][\"P(S)\"] = 0.5*(skill_grads[skill][\"P(S)\"] + grad* w *(-P_skill[0]))\n",
    "        skill_grads[skill][\"P(T)\"] = 0.5*(skill_grads[skill][\"P(T)\"] + grad* w * (1 - P_skill[0])*((1 - P_skill[2])- P_skill[1]))\n",
    "\n",
    "\n",
    "    return skill_grads, user_grads, weight_grads, likelihood, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M-Step: Update parameters\n",
    "def maximization_step(skill_params, user_params, skill_grads, user_grads, weight_grads, learning_rate=0.01, beta1=0.9, beta2=0.999, epsilon=1e-8, t=1):\n",
    "    # Adam accumulators\n",
    "    skill_m = defaultdict(lambda: {\"P(L)\": 0, \"P(T)\": 0, \"P(G)\": 0, \"P(S)\": 0})\n",
    "    skill_v = defaultdict(lambda: {\"P(L)\": 0, \"P(T)\": 0, \"P(G)\": 0, \"P(S)\": 0})\n",
    "    user_m = defaultdict(lambda: defaultdict(lambda: {\"P(L)\": 0, \"P(T)\": 0, \"P(G)\": 0, \"P(S)\": 0}))\n",
    "    user_v = defaultdict(lambda: defaultdict(lambda: {\"P(L)\": 0, \"P(T)\": 0, \"P(G)\": 0, \"P(S)\": 0}))\n",
    "\n",
    "\n",
    "    # Apply SGD for user-specific updates\n",
    "    for user_id, skills in user_grads.items():\n",
    "        for skill, grads in skills.items():\n",
    "            for param, grad in grads.items():\n",
    "                    m = user_m[user_id][skill][param]\n",
    "                    v = user_v[user_id][skill][param]\n",
    "\n",
    "                    m = beta1 * m + (1 - beta1) * grad\n",
    "                    v = beta2 * v + (1 - beta2) * (grad ** 2)\n",
    "                    m_hat = m / (1 - beta1 ** t)\n",
    "                    v_hat = v / (1 - beta2 ** t)\n",
    "\n",
    "                    user_params[user_id][skill][param] = np.clip(user_params[user_id][skill][param] - learning_rate * m_hat / (np.sqrt(v_hat) + epsilon), 0, 1)\n",
    "                    user_m[user_id][skill][param] = m\n",
    "                    user_v[user_id][skill][param] = v\n",
    "\n",
    "    # Apply batch updates for skill-specific parameters\n",
    "    for skill, grads in skill_grads.items():\n",
    "        for param, grad in grads.items():\n",
    "            m = skill_m[skill][param]\n",
    "            v = skill_v[skill][param]\n",
    "\n",
    "            m = beta1 * m + (1 - beta1) * grad\n",
    "            v = beta2 * v + (1 - beta2) * (grad ** 2)\n",
    "            m_hat = m / (1 - beta1 ** t)\n",
    "            v_hat = v / (1 - beta2 ** t)\n",
    "\n",
    "            skill_params[skill][param] = np.clip(skill_params[skill][param] - learning_rate * m_hat / (np.sqrt(v_hat) + epsilon), 0, 1)\n",
    "            skill_m[skill][param] = m\n",
    "            skill_v[skill][param] = v\n",
    "            \n",
    "    # Update user weights\n",
    "    for user_id in user_params.keys():\n",
    "        user_params[user_id]['weight'] = np.clip(user_params[user_id]['weight'] - learning_rate * weight_grads[user_id], 0, 1)\n",
    "\n",
    "    return skill_params, user_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parent-Child Constraints\n",
    "def enforce_constraints(user_params, skill_params, skills):\n",
    "    for skill, skill_data in skills.items():\n",
    "        parents = skill_data[1]\n",
    "        for parent in parents:\n",
    "            if skill_params[skill][\"P(L)\"] >= skill_params[parent][\"P(L)\"]:\n",
    "                skill_params[skill][\"P(L)\"] = skill_params[parent][\"P(L)\"] - 0.01 \n",
    "            for user in user_params:\n",
    "                parent_prob = user_params[user][parent][\"P(L)\"]\n",
    "                child_prob = user_params[user][skill][\"P(L)\"]\n",
    "                if child_prob >= parent_prob:\n",
    "                    user_params[user][skill][\"P(L)\"] = parent_prob - 0.01  # Apply heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projection\n",
    "def project_params(params, par_type):\n",
    "    for key, param_set in params.items():\n",
    "        if  par_type == \"user\":\n",
    "                for skill, ps in param_set.items():\n",
    "                    if skill == 'weight':\n",
    "                        params[key][skill] = np.clip(params[key][skill], 0, 1)\n",
    "                    else:\n",
    "                        for param in ps:\n",
    "                            params[key][skill][param] = np.clip(params[key][skill][param], 0, 1)\n",
    "        elif par_type == \"skill\":\n",
    "            if type(param_set) != dict:\n",
    "                a = 3\n",
    "            for param in param_set:\n",
    "                params[key][param] = np.clip(params[key][param], 0, 1)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid parameter type. Must be 'user' or 'skill'.\")\n",
    "            \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_em_with_sgd(interaction_log, skills, max_iter=50, learning_rate=0.005):\n",
    "    skill_params, user_params = initialize_params(skills, interaction_log[\"username\"].unique())\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        skill_grads, user_grads, weight_grads, likelihood, loss = expectation_step(interaction_log, skill_params, user_params)\n",
    "        skill_params, user_params = maximization_step(skill_params, user_params, skill_grads, user_grads, weight_grads,learning_rate=learning_rate)\n",
    "        skill_params = project_params(skill_params, \"skill\")\n",
    "        user_params = project_params(user_params, \"user\")\n",
    "        if i % 5 == 0:\n",
    "            print(f\"Iteration {i + 1}, Log-likelihood: {likelihood}, Loss: {loss}\")\n",
    "\n",
    "    return skill_params, user_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, Log-likelihood: 2206.767275063034, Loss: 381.8840055187332\n",
      "Iteration 6, Log-likelihood: 2095.5470104151523, Loss: 394.58455497186947\n",
      "Iteration 11, Log-likelihood: 1995.008536078541, Loss: 409.774318702277\n",
      "Iteration 16, Log-likelihood: 1906.5903717817246, Loss: 429.0131818834982\n",
      "Iteration 21, Log-likelihood: 1827.0765729802176, Loss: 450.1692966486946\n",
      "Iteration 26, Log-likelihood: 1756.5593681763173, Loss: 473.50419326890244\n",
      "Iteration 31, Log-likelihood: 1693.787836336294, Loss: 498.463275203306\n",
      "Iteration 36, Log-likelihood: 1638.2887833657903, Loss: 524.7678015235482\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3566677/3623131440.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;31m# Run the EM Algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mskill_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_em_with_sgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskills\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Output Results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3566677/806440229.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(interaction_log, skills, max_iter, learning_rate)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_em_with_sgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteraction_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskills\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.003\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mskill_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskills\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteraction_log\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"username\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mskill_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlikelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpectation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteraction_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskill_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mskill_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaximization_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskill_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskill_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_grads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mskill_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproject_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskill_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"skill\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0muser_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproject_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3566677/2946793778.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(interaction_log, skill_params, user_params)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mskill_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"P(L)\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"P(T)\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"P(G)\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"P(S)\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0muser_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"P(L)\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"P(T)\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"P(G)\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"P(S)\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mweight_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0muser_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muser_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mlikelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpectations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteraction_log\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mskill_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Log-likelihood NaN detected! Check parameter updates.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3566677/2134422289.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(interaction_log, skill_params, user_params)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlog_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteraction_log\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mskill_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlog_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mexpectations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minteraction_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0muser_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"username\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mskill_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"skill\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mcorrectness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"correct\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/mygitsDaTu/AITutor_SeqModeling/myenv/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1396\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m         \u001b[0musing_cow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1400\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1401\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0musing_cow\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_single_block\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m                 \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_references\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/mygitsDaTu/AITutor_SeqModeling/myenv/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, other, method, **kwargs)\u001b[0m\n\u001b[1;32m   5953\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5955\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallows_duplicate_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallows_duplicate_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5956\u001b[0m             \u001b[0;31m# For subclasses using _metadata.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5957\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5958\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5959\u001b[0m                 \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run the EM Algorithm\n",
    "skill_params, user_params = run_em_with_sgd(df.iloc[:2000], skills)\n",
    "\n",
    "# Output Results\n",
    "print(\"Final Skill Parameters:\")\n",
    "for skill, params in skill_params.items():\n",
    "    print(skill, params)\n",
    "\n",
    "print(\"\\nFinal User Parameters:\")\n",
    "for user_id, user_data in user_params.items():\n",
    "    print(user_id)\n",
    "    for skill, params in user_data.items():\n",
    "        print(f\"  {skill}: {params}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
