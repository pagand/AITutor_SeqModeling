{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "import sys\n",
    "import datetime\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/local-scratch/localhome/pagand/projects/DaTu/ML/logda\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "# cwd = os.chdir(os.path.join(os.getcwd(), \"logda\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  username           Date and Time Time since session started\\n(h:mm:ss)  \\\n",
      "0       a1 2023-08-03 09:34:57.240                              00:00:00   \n",
      "1       a1 2023-08-03 09:35:00.152                              00:00:02   \n",
      "2       a1 2023-08-03 09:35:30.167                              00:00:32   \n",
      "3       a1 2023-08-03 09:41:32.112                              00:06:34   \n",
      "4       a1 2023-08-03 09:41:32.112                              00:06:34   \n",
      "\n",
      "         space                     action  \n",
      "0          NaN                 User login  \n",
      "1   /courses/1                  Load page  \n",
      "2  EDA Toolbox  Load default toolbox page  \n",
      "3    Problem 1              Start problem  \n",
      "4    Problem 1               First answer  \n"
     ]
    }
   ],
   "source": [
    "File_xlsx = \"data/integration_log_group_a.xlsx\"\n",
    "\n",
    "df = pd.read_excel(File_xlsx)\n",
    "df = df.iloc[:, :-1] \n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      username           Date and Time Time since session started\\n(h:mm:ss)  \\\n",
      "0           a1 2023-08-03 09:34:57.240                              00:00:00   \n",
      "1           a1 2023-08-03 09:35:00.152                              00:00:02   \n",
      "2           a1 2023-08-03 09:35:30.167                              00:00:32   \n",
      "3           a1 2023-08-03 09:41:32.112                              00:06:34   \n",
      "4           a1 2023-08-03 09:41:32.112                              00:06:34   \n",
      "...        ...                     ...                                   ...   \n",
      "22209      b51 2023-09-21 12:05:15.996                              02:37:57   \n",
      "22210      b51 2023-09-21 12:05:39.705                              02:38:21   \n",
      "22211      b51 2023-09-21 21:00:11.019                              11:32:52   \n",
      "22212      b51 2023-09-21 21:00:11.043                              11:32:52   \n",
      "22213      b51 2023-09-22 07:32:32.204                              22:05:14   \n",
      "\n",
      "             space                     action  \n",
      "0              NaN                 User login  \n",
      "1       /courses/1                  Load page  \n",
      "2      EDA Toolbox  Load default toolbox page  \n",
      "3        Problem 1              Start problem  \n",
      "4        Problem 1               First answer  \n",
      "...            ...                        ...  \n",
      "22209    Problem 3              Change answer  \n",
      "22210    Problem 3             Submit problem  \n",
      "22211   /courses/1                  Load page  \n",
      "22212   /courses/1                  Load page  \n",
      "22213   /courses/1                  Load page  \n",
      "\n",
      "[40941 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# augment group_b at the end of it\n",
    "File_xlsx = \"data/integration_log_group_b.xlsx\"\n",
    "\n",
    "\n",
    "df_b = pd.read_excel(File_xlsx)\n",
    "df_b = df_b.iloc[:, :-1]\n",
    "\n",
    "df = pd.concat([df, df_b], axis=0)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          score1  score2    score3\n",
      "username                          \n",
      "a1        0.6875    0.45  0.583333\n",
      "a2        0.4375    0.00  0.000000\n",
      "a3        0.6250    0.35  0.166667\n",
      "a4        0.5000    0.45  0.000000\n",
      "a5        0.4375    0.30  0.194444\n",
      "...          ...     ...       ...\n",
      "b46       0.8750    0.45  0.194444\n",
      "b47       0.5000    0.30  0.555556\n",
      "b48       0.3125    0.40  0.138889\n",
      "b49       0.4375    0.40  0.472222\n",
      "b51       0.3750    0.40  0.444444\n",
      "\n",
      "[89 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# read the scores\n",
    "File_score_xlsx = [\"data/Groupa_scores.xlsx\", \"data/Groupb_scores.xlsx\"]\n",
    "\n",
    "for i in range(2):\n",
    "    # read the scores\n",
    "    read_file = pd.read_excel(File_score_xlsx[i])\n",
    "\n",
    "    # change the first column name to username\n",
    "    read_file.rename(columns={\"Participant ID's\":'username', 'Problem 1 (Score out of 16)': 'score1',\n",
    "                            'Problem 2 (Score out of 20)': 'score2', 'Problem 3 (Score out of 18)': 'score3' }, inplace=True)\n",
    "    \n",
    "    # use the username as the index\n",
    "    read_file.set_index('username', inplace=True)\n",
    "    # devide first column by 16, second column by 20, third column by 18\n",
    "    read_file['score1'] = read_file['score1'].div(16)\n",
    "    read_file['score2'] = read_file['score2'].div(20)\n",
    "    read_file['score3'] = read_file['score3'].div(18)\n",
    "    if i:\n",
    "        read_file = read_file[:-4]\n",
    "        score_df = pd.concat([score_df, read_file], axis=0)\n",
    "    else:\n",
    "        read_file = read_file[:-3]\n",
    "        score_df = read_file.copy()\n",
    "\n",
    "print(score_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    username  problem     score\n",
      "0         a1        1  0.687500\n",
      "1         a1        2  0.450000\n",
      "2         a1        3  0.583333\n",
      "3         a2        1  0.437500\n",
      "4         a2        2  0.000000\n",
      "..       ...      ...       ...\n",
      "262      b49        2  0.400000\n",
      "263      b49        3  0.472222\n",
      "264      b51        1  0.375000\n",
      "265      b51        2  0.400000\n",
      "266      b51        3  0.444444\n",
      "\n",
      "[267 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# convert the score_df to a df series the value is the score.\n",
    "# it should look like this:\n",
    "# username probelm score\n",
    "# a1        1       0.5\n",
    "# a1        2       0.6\n",
    "# a1        3       0.7\n",
    "# a2        1       0.6\n",
    "\n",
    "\n",
    "score_df = score_df.stack().reset_index()\n",
    "score_df.columns = ['username', 'problem', 'score']\n",
    "# replace score1, score2, score3 with 1, 2, 3\n",
    "score_df['problem'] = score_df['problem'].str.replace('score', '').astype(int)\n",
    "print(score_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have a copy of the original df (run to reset)\n",
    "if 'df_org' not in globals():\n",
    "    df_org = df.copy()\n",
    "else:\n",
    "    df = df_org.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action\n",
      "Change answer                      11370\n",
      "First answer                        4569\n",
      "Update confidence                   2996\n",
      "Request another hint                2712\n",
      "Streamlit interaction               2451\n",
      "New answer explanation              2108\n",
      "Auto-save log                       1874\n",
      "Request first hint                  1788\n",
      "Paste answer                        1662\n",
      "Update answer explanation           1622\n",
      "Load default toolbox page           1576\n",
      "Load page                           1306\n",
      "Freeform code run                   1258\n",
      "Run code error                       624\n",
      "Run code                             577\n",
      "Start reading sub-module             448\n",
      "User request                         400\n",
      "Chatbot response                     400\n",
      "Respond to hint feedback             385\n",
      "Start problem                        254\n",
      "Submit problem                       235\n",
      "Complete sub-module                  122\n",
      "User login                           111\n",
      "Save note                             56\n",
      "Stop reading sub-module preview       28\n",
      "User logout                            9\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# get the unique values of the column action\n",
    "unique_actions = df.action.unique()\n",
    "# peint unique actions with their counts\n",
    "print(df['action'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action\n",
      "Change answer                11370\n",
      "First answer                  4569\n",
      "Update confidence             2996\n",
      "Request another hint          2712\n",
      "Streamlit interaction         2451\n",
      "New answer explanation        2108\n",
      "Request first hint            1788\n",
      "Paste answer                  1662\n",
      "Update answer explanation     1622\n",
      "Freeform code run             1258\n",
      "Run code                       577\n",
      "User request                   400\n",
      "Respond to hint feedback       385\n",
      "Complete sub-module            122\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# remove entries in df that are 'Save note','Auto-save log', 'Load default toolbox page', 'Load page', 'Run code error', 'Start reading sub-module', 'User login', 'User logout',  'Start problem', 'Submit problem'\n",
    "df = df[~df['action'].isin(['Save note','Auto-save log', 'Load default toolbox page', 'Load page', 'Run code error', 'Start reading sub-module', 'User login', 'User logout',  'Start problem', 'Submit problem', 'Stop reading sub-module preview', 'Chatbot response'])]\n",
    "# get the unique values of the column action\n",
    "unique_actions = df.action.unique()\n",
    "# peint unique actions with their counts\n",
    "print(df['action'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "space\n",
       "Problem 3      10570\n",
       "Problem 2      10530\n",
       "Problem 1       9370\n",
       "EDA Toolbox     2451\n",
       "Code Editor      577\n",
       "AI Chatbot       400\n",
       "Library          122\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['space'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "space\n",
       "1    11807\n",
       "2    11416\n",
       "3    10797\n",
       "Name: count, dtype: Int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['space'] = df['space'].replace('Problem 3', 3)\n",
    "df['space'] = df['space'].replace('Problem 2', 2)\n",
    "df['space'] = df['space'].replace('Problem 1', 1)\n",
    "# if the space is not int, make it np.nan\n",
    "df['space'] = pd.to_numeric(df['space'], errors='coerce')\n",
    "# # if the space is not 1,2,3 change it to the value of the previous row\n",
    "df['space'] = df['space'].fillna(method='ffill')\n",
    "# change dtyle of space to Int64\n",
    "df['space'] = df['space'].astype('Int64')\n",
    "df['space'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for type(df.iloc[i, 2]) if is not datetime.time, then convert it to datetime.time\n",
    "\n",
    "df = df.drop(columns=['Date and Time']) \n",
    "for i in range(len(df)):\n",
    "    if type(df.iloc[i, 1]) != datetime.time:\n",
    "        df.iloc[i, 1] = df.iloc[i, 1].time()\n",
    "# rename second column to time\n",
    "df.rename(columns={df.columns[1]: 'time'}, inplace=True)\n",
    "df.rename(columns={df.columns[2]: 'problem'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>time</th>\n",
       "      <th>problem</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a1</td>\n",
       "      <td>00:06:34</td>\n",
       "      <td>1</td>\n",
       "      <td>FA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a1</td>\n",
       "      <td>00:06:36</td>\n",
       "      <td>1</td>\n",
       "      <td>FE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a1</td>\n",
       "      <td>00:06:49</td>\n",
       "      <td>1</td>\n",
       "      <td>UE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a1</td>\n",
       "      <td>00:07:13</td>\n",
       "      <td>1</td>\n",
       "      <td>UE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a1</td>\n",
       "      <td>00:07:38</td>\n",
       "      <td>1</td>\n",
       "      <td>UE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22205</th>\n",
       "      <td>b51</td>\n",
       "      <td>02:37:36</td>\n",
       "      <td>3</td>\n",
       "      <td>UH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22206</th>\n",
       "      <td>b51</td>\n",
       "      <td>02:37:36</td>\n",
       "      <td>3</td>\n",
       "      <td>UH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22207</th>\n",
       "      <td>b51</td>\n",
       "      <td>02:37:45</td>\n",
       "      <td>3</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22208</th>\n",
       "      <td>b51</td>\n",
       "      <td>02:37:47</td>\n",
       "      <td>3</td>\n",
       "      <td>UA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22209</th>\n",
       "      <td>b51</td>\n",
       "      <td>02:37:57</td>\n",
       "      <td>3</td>\n",
       "      <td>UA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34020 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      username      time  problem action\n",
       "4           a1  00:06:34        1     FA\n",
       "5           a1  00:06:36        1     FE\n",
       "6           a1  00:06:49        1     UE\n",
       "7           a1  00:07:13        1     UE\n",
       "8           a1  00:07:38        1     UE\n",
       "...        ...       ...      ...    ...\n",
       "22205      b51  02:37:36        3     UH\n",
       "22206      b51  02:37:36        3     UH\n",
       "22207      b51  02:37:45        3     PA\n",
       "22208      b51  02:37:47        3     UA\n",
       "22209      b51  02:37:57        3     UA\n",
       "\n",
       "[34020 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a map for actions\n",
    "# create a map for actions\n",
    "action_map = {\n",
    "    'Change answer': 'UA',\n",
    "    'First answer': 'FA',\n",
    "    'Paste answer': 'PA',\n",
    "    'Request first hint': 'FH',\n",
    "    'Request another hint': 'UH',\n",
    "    'Respond to hint feedback': 'RH',\n",
    "    'New answer explanation': 'FE',\n",
    "    'Update answer explanation': 'UE',\n",
    "    'Freeform code run': 'RF',\n",
    "    'Run code': 'RC',\n",
    "    'User request': 'B',\n",
    "    'Update confidence': 'C',\n",
    "    'Complete sub-module': 'M',\n",
    "    'Streamlit interaction': 'S'\n",
    "}\n",
    "\n",
    "# map the actions\n",
    "df['action'] = df['action'].map(action_map)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>problem</th>\n",
       "      <th>action</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a1</td>\n",
       "      <td>1</td>\n",
       "      <td>FA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a1</td>\n",
       "      <td>1</td>\n",
       "      <td>FE</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a1</td>\n",
       "      <td>1</td>\n",
       "      <td>UE</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a1</td>\n",
       "      <td>1</td>\n",
       "      <td>UE</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a1</td>\n",
       "      <td>1</td>\n",
       "      <td>UE</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22205</th>\n",
       "      <td>b51</td>\n",
       "      <td>3</td>\n",
       "      <td>UH</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22206</th>\n",
       "      <td>b51</td>\n",
       "      <td>3</td>\n",
       "      <td>UH</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22207</th>\n",
       "      <td>b51</td>\n",
       "      <td>3</td>\n",
       "      <td>PA</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22208</th>\n",
       "      <td>b51</td>\n",
       "      <td>3</td>\n",
       "      <td>UA</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22209</th>\n",
       "      <td>b51</td>\n",
       "      <td>3</td>\n",
       "      <td>UA</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34020 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      username  problem action  duration\n",
       "4           a1        1     FA       NaN\n",
       "5           a1        1     FE       2.0\n",
       "6           a1        1     UE      13.0\n",
       "7           a1        1     UE      24.0\n",
       "8           a1        1     UE      25.0\n",
       "...        ...      ...    ...       ...\n",
       "22205      b51        3     UH       0.0\n",
       "22206      b51        3     UH       0.0\n",
       "22207      b51        3     PA       9.0\n",
       "22208      b51        3     UA       2.0\n",
       "22209      b51        3     UA      10.0\n",
       "\n",
       "[34020 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in column time, compute the difference between the current row and the previous row in seconds, only if the username and probem are the same\n",
    "# otherwise, put np.nan\n",
    "df['duration']=np.nan\n",
    "for i in range(1, len(df)):\n",
    "    if df.iloc[i, 0] == df.iloc[i-1, 0] and df.iloc[i, 2] == df.iloc[i-1, 2]:\n",
    "        df.iloc[i, 4] = (datetime.datetime.combine(datetime.datetime.today(), df.iloc[i, 1])\n",
    "            - datetime.datetime.combine(datetime.datetime.today(), df.iloc[i-1, 1])).total_seconds()\n",
    "# remove the time column\n",
    "df = df.drop(columns=['time'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there is a negative value in the duration column, replace it with np.nan\n",
    "df['duration'] = df['duration'].apply(lambda x: np.nan if x < 0 else x)\n",
    "# if it is greater than 1200, replace it with np.nan\n",
    "df['duration'] = df['duration'].apply(lambda x: np.nan if x > 1200 else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>problem</th>\n",
       "      <th>action</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a1</td>\n",
       "      <td>1</td>\n",
       "      <td>FA</td>\n",
       "      <td>24.81457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a1</td>\n",
       "      <td>1</td>\n",
       "      <td>FE</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a1</td>\n",
       "      <td>1</td>\n",
       "      <td>UE</td>\n",
       "      <td>13.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a1</td>\n",
       "      <td>1</td>\n",
       "      <td>UE</td>\n",
       "      <td>24.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a1</td>\n",
       "      <td>1</td>\n",
       "      <td>UE</td>\n",
       "      <td>25.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22205</th>\n",
       "      <td>b51</td>\n",
       "      <td>3</td>\n",
       "      <td>UH</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22206</th>\n",
       "      <td>b51</td>\n",
       "      <td>3</td>\n",
       "      <td>UH</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22207</th>\n",
       "      <td>b51</td>\n",
       "      <td>3</td>\n",
       "      <td>PA</td>\n",
       "      <td>9.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22208</th>\n",
       "      <td>b51</td>\n",
       "      <td>3</td>\n",
       "      <td>UA</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22209</th>\n",
       "      <td>b51</td>\n",
       "      <td>3</td>\n",
       "      <td>UA</td>\n",
       "      <td>10.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34020 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      username  problem action  duration\n",
       "4           a1        1     FA  24.81457\n",
       "5           a1        1     FE   2.00000\n",
       "6           a1        1     UE  13.00000\n",
       "7           a1        1     UE  24.00000\n",
       "8           a1        1     UE  25.00000\n",
       "...        ...      ...    ...       ...\n",
       "22205      b51        3     UH   0.00000\n",
       "22206      b51        3     UH   0.00000\n",
       "22207      b51        3     PA   9.00000\n",
       "22208      b51        3     UA   2.00000\n",
       "22209      b51        3     UA  10.00000\n",
       "\n",
       "[34020 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# impute the missing values in duration with the mean of the duration in the same problem and username\n",
    "df['duration'] = df['duration'].fillna(df.groupby(['username', 'problem'])['duration'].transform('mean'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>34020.0</td>\n",
       "      <td>34020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.970312</td>\n",
       "      <td>19.510460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.814599</td>\n",
       "      <td>47.330066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1198.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        problem      duration\n",
       "count   34020.0  34020.000000\n",
       "mean   1.970312     19.510460\n",
       "std    0.814599     47.330066\n",
       "min         1.0      0.000000\n",
       "25%         1.0      2.000000\n",
       "50%         2.0      5.000000\n",
       "75%         3.0     19.000000\n",
       "max         3.0   1198.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe the df \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>problem</th>\n",
       "      <th>action</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a1</td>\n",
       "      <td>1</td>\n",
       "      <td>FA</td>\n",
       "      <td>T5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a1</td>\n",
       "      <td>1</td>\n",
       "      <td>FE</td>\n",
       "      <td>T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a1</td>\n",
       "      <td>1</td>\n",
       "      <td>UE</td>\n",
       "      <td>T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a1</td>\n",
       "      <td>1</td>\n",
       "      <td>UE</td>\n",
       "      <td>T5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a1</td>\n",
       "      <td>1</td>\n",
       "      <td>UE</td>\n",
       "      <td>T5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22205</th>\n",
       "      <td>b51</td>\n",
       "      <td>3</td>\n",
       "      <td>UH</td>\n",
       "      <td>T0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22206</th>\n",
       "      <td>b51</td>\n",
       "      <td>3</td>\n",
       "      <td>UH</td>\n",
       "      <td>T0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22207</th>\n",
       "      <td>b51</td>\n",
       "      <td>3</td>\n",
       "      <td>PA</td>\n",
       "      <td>T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22208</th>\n",
       "      <td>b51</td>\n",
       "      <td>3</td>\n",
       "      <td>UA</td>\n",
       "      <td>T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22209</th>\n",
       "      <td>b51</td>\n",
       "      <td>3</td>\n",
       "      <td>UA</td>\n",
       "      <td>T2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34020 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      username  problem action duration\n",
       "4           a1        1     FA       T5\n",
       "5           a1        1     FE       T1\n",
       "6           a1        1     UE       T3\n",
       "7           a1        1     UE       T5\n",
       "8           a1        1     UE       T5\n",
       "...        ...      ...    ...      ...\n",
       "22205      b51        3     UH       T0\n",
       "22206      b51        3     UH       T0\n",
       "22207      b51        3     PA       T2\n",
       "22208      b51        3     UA       T1\n",
       "22209      b51        3     UA       T2\n",
       "\n",
       "[34020 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decode the duration colomn as follows:\n",
    "# 0-1: '0'\n",
    "# 1-5: '1'\n",
    "# 5-10: '2'\n",
    "# 10-15: '3'\n",
    "# 15-20: '4'\n",
    "# 20-30: ''5'\n",
    "# 30-60: '6'\n",
    "# 60-120: '7'\n",
    "# 120-300: '8'\n",
    "# 300-MAX: 'MAX'\n",
    "\n",
    "df['duration'] = pd.cut(df['duration'], bins=[-0.1, 1, 5, 10, 15, 20, 30, 60, 120, 300, df['duration'].max()], labels=['T0', 'T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7', 'T8', 'TMAX'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sequence episode we have 254\n",
      "number of scores we have  267\n"
     ]
    }
   ],
   "source": [
    "# for each username and problem, create a numpy array of the pair of actions, duration in the order they appear\n",
    "# Then put the numpy array in a dictionary with the key as the username and problem\n",
    "# example:\n",
    "# (a1, 1): [UA, T0, FA, T1, PA, T2]\n",
    "# (a1, 2): [UA, T0, FA, T1, PA, T2, FH, T3]\n",
    "# (a2, 1): [UA, T0, FA, T1, PA, T2, FH, T3, UH, T4]\n",
    "\n",
    "# create a dictionary\n",
    "df_dict = {}\n",
    "for i in range(len(df)):\n",
    "    if (df.iloc[i, 0], df.iloc[i, 1]) in df_dict:\n",
    "        df_dict[(df.iloc[i, 0], df.iloc[i, 1])].extend([df.iloc[i, 2], df.iloc[i, 3]])\n",
    "    else:\n",
    "        df_dict[(df.iloc[i, 0], df.iloc[i, 1])] = ['Q{}'.format(df.iloc[i, 1]), df.iloc[i, 2], df.iloc[i, 3]]\n",
    "\n",
    "# # convert the list to numpy array\n",
    "# for key in df_dict.keys():\n",
    "#     df_dict[key] = np.array(df_dict[key])\n",
    "     \n",
    "\n",
    "print(\"number of sequence episode we have\", len(df_dict.keys()))\n",
    "print(\"number of scores we have \", len(score_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254 254\n"
     ]
    }
   ],
   "source": [
    "# for each key in the dictionary, find the score and append the values to a list (sequences) and the score to another list (scores)\n",
    "# len(sequences) should be equal to len(scores)\n",
    "\n",
    "sequences = []\n",
    "scores = []\n",
    "for key in df_dict.keys():\n",
    "        sequences.append(df_dict[key])\n",
    "        scores.append(score_df[(score_df['username'] == key[0]) & (score_df['problem'] == key[1])]['score'].values.tolist())\n",
    "\n",
    "print(len(sequences), len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if scores is empty, replace it with 0\n",
    "scores = [[0] if len(x) == 0 else x for x in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localhome/pagand/projects/DaTu/ML/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "import wandb\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpedramagand\u001b[0m (\u001b[33mmarslab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/local-scratch/localhome/pagand/projects/DaTu/ML/logda/wandb/run-20240404_172202-nca3zkes</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/marslab/DaTu_prediction/runs/nca3zkes' target=\"_blank\">bert-base-uncased</a></strong> to <a href='https://wandb.ai/marslab/DaTu_prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/marslab/DaTu_prediction' target=\"_blank\">https://wandb.ai/marslab/DaTu_prediction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/marslab/DaTu_prediction/runs/nca3zkes' target=\"_blank\">https://wandb.ai/marslab/DaTu_prediction/runs/nca3zkes</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/marslab/DaTu_prediction/runs/nca3zkes?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7ff2e0a13880>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"DaTu_prediction\", entity=\"marslab\", name = \"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=1)  # num_labels=1 for regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30538, 768)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokens = ['UA','FA','PA','FH', 'UH', 'RH','FE', 'UE','RF', 'RC', 'B', 'C','M', 'S',\n",
    "    'T0', 'T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7', 'T8', 'TMAX', \n",
    "    'Q1', 'Q2', 'Q3']\n",
    "\n",
    "tokenizer.add_tokens(new_tokens)\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))  # Adjust model embedding size to include new tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DaTuDataset(Dataset):\n",
    "    def __init__(self, sequences, scores, tokenizer, max_length=512):\n",
    "        self.sequences = sequences\n",
    "        self.scores = scores\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        score = self.scores[idx]\n",
    "        \n",
    "        # Tokenize the sequence\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            sequence,\n",
    "            add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "            max_length=self.max_length,  # Max length to truncate/pad\n",
    "            padding='max_length',  # Pad to max_length\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'  # Return PyTorch tensors\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'],\n",
    "            'attention_mask': inputs['attention_mask'],\n",
    "            'labels': torch.tensor(score, dtype=torch.float)\n",
    "        }\n",
    "        #inputs.input_ids.squeeze(0), inputs.attention_mask.squeeze(0), torch.tensor(score, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30538, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chceck if cuda is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset and dataloader\n",
    "dataset = DaTuDataset(sequences,  scores, tokenizer)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=None)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False, collate_fn=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localhome/pagand/projects/DaTu/ML/.venv/lib/python3.8/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "# Optimizer and Learning Rate Scheduler\n",
    "epochs = 16\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_val_loop(model, train_dataloader, val_dataloader, optimizer, scheduler, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        i = 0\n",
    "        for batch in train_dataloader:\n",
    "\n",
    "            batch = {k: v.squeeze(1).to(device) for k, v in batch.items()}  # Move batch to device\n",
    "            outputs = model(**batch)\n",
    "\n",
    "            # input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "            # outputs = model(input_ids, attention_mask=attention_mask, labels=labels.float())\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Gradient clipping\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "        wandb.log({\"train_loss\": avg_train_loss})\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        for batch in val_dataloader:\n",
    "            i+=1\n",
    "            batch = {k: v.squeeze(1).to(device) for k, v in batch.items()}  # Move batch to device\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**batch)\n",
    "                loss = outputs.loss\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_dataloader)\n",
    "        wandb.log({\"validation_loss\": avg_val_loss})\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} | Train Loss: {avg_train_loss:.3f} | Validation Loss: {avg_val_loss:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16 | Train Loss: 0.090 | Validation Loss: 0.092\n",
      "Epoch 2/16 | Train Loss: 0.102 | Validation Loss: 0.043\n",
      "Epoch 3/16 | Train Loss: 0.077 | Validation Loss: 0.056\n",
      "Epoch 4/16 | Train Loss: 0.085 | Validation Loss: 0.038\n",
      "Epoch 5/16 | Train Loss: 0.066 | Validation Loss: 0.040\n",
      "Epoch 6/16 | Train Loss: 0.074 | Validation Loss: 0.047\n",
      "Epoch 7/16 | Train Loss: 0.070 | Validation Loss: 0.064\n",
      "Epoch 8/16 | Train Loss: 0.067 | Validation Loss: 0.041\n",
      "Epoch 9/16 | Train Loss: 0.069 | Validation Loss: 0.037\n",
      "Epoch 10/16 | Train Loss: 0.061 | Validation Loss: 0.037\n",
      "Epoch 11/16 | Train Loss: 0.057 | Validation Loss: 0.042\n",
      "Epoch 12/16 | Train Loss: 0.060 | Validation Loss: 0.038\n",
      "Epoch 13/16 | Train Loss: 0.058 | Validation Loss: 0.041\n",
      "Epoch 14/16 | Train Loss: 0.058 | Validation Loss: 0.045\n",
      "Epoch 15/16 | Train Loss: 0.057 | Validation Loss: 0.038\n",
      "Epoch 16/16 | Train Loss: 0.055 | Validation Loss: 0.040\n"
     ]
    }
   ],
   "source": [
    "train_val_loop(model, train_dataloader, val_dataloader, optimizer, scheduler, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simpler model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:nca3zkes) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>▆█▄▅▃▄▃▃▃▂▁▂▁▁▁▁</td></tr><tr><td>validation_loss</td><td>█▂▃▁▁▂▄▁▁▁▂▁▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.0553</td></tr><tr><td>validation_loss</td><td>0.04028</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bert-base-uncased</strong> at: <a href='https://wandb.ai/marslab/DaTu_prediction/runs/nca3zkes' target=\"_blank\">https://wandb.ai/marslab/DaTu_prediction/runs/nca3zkes</a><br/> View project at: <a href='https://wandb.ai/marslab/DaTu_prediction' target=\"_blank\">https://wandb.ai/marslab/DaTu_prediction</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240404_172202-nca3zkes/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:nca3zkes). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/local-scratch/localhome/pagand/projects/DaTu/ML/logda/wandb/run-20240404_172410-8fvo2sbo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/marslab/DaTu_prediction/runs/8fvo2sbo' target=\"_blank\">distilbert-base-uncased</a></strong> to <a href='https://wandb.ai/marslab/DaTu_prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/marslab/DaTu_prediction' target=\"_blank\">https://wandb.ai/marslab/DaTu_prediction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/marslab/DaTu_prediction/runs/8fvo2sbo' target=\"_blank\">https://wandb.ai/marslab/DaTu_prediction/runs/8fvo2sbo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/marslab/DaTu_prediction/runs/8fvo2sbo?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7ff2e06a2160>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"DaTu_prediction\", entity=\"marslab\", name = \"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30538, 768)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokens = ['UA','FA','PA','FH', 'UH', 'RH','FE', 'UE','RF', 'RC', 'B', 'C','M', 'S',\n",
    "    'T0', 'T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7', 'T8', 'TMAX', \n",
    "    'Q1', 'Q2', 'Q3']\n",
    "tokenizer.add_tokens(new_tokens)\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))  # Adjust model embedding size to include new tokens\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional\n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.3),  # Increase dropout\n",
    "    nn.Linear(model.classifier.in_features, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30538, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset and dataloader\n",
    "dataset = DaTuDataset(sequences,  scores, tokenizer)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=None)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False, collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localhome/pagand/projects/DaTu/ML/.venv/lib/python3.8/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "epochs = 16\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16 | Train Loss: 0.079 | Validation Loss: 0.078\n",
      "Epoch 2/16 | Train Loss: 0.061 | Validation Loss: 0.062\n",
      "Epoch 3/16 | Train Loss: 0.058 | Validation Loss: 0.053\n",
      "Epoch 4/16 | Train Loss: 0.055 | Validation Loss: 0.049\n",
      "Epoch 5/16 | Train Loss: 0.060 | Validation Loss: 0.066\n",
      "Epoch 6/16 | Train Loss: 0.057 | Validation Loss: 0.053\n",
      "Epoch 7/16 | Train Loss: 0.050 | Validation Loss: 0.055\n",
      "Epoch 8/16 | Train Loss: 0.054 | Validation Loss: 0.049\n",
      "Epoch 9/16 | Train Loss: 0.046 | Validation Loss: 0.047\n",
      "Epoch 10/16 | Train Loss: 0.042 | Validation Loss: 0.045\n",
      "Epoch 11/16 | Train Loss: 0.035 | Validation Loss: 0.044\n",
      "Epoch 12/16 | Train Loss: 0.039 | Validation Loss: 0.047\n",
      "Epoch 13/16 | Train Loss: 0.031 | Validation Loss: 0.048\n",
      "Epoch 14/16 | Train Loss: 0.032 | Validation Loss: 0.045\n",
      "Epoch 15/16 | Train Loss: 0.029 | Validation Loss: 0.045\n",
      "Epoch 16/16 | Train Loss: 0.028 | Validation Loss: 0.044\n"
     ]
    }
   ],
   "source": [
    "train_val_loop(model, train_dataloader, val_dataloader, optimizer, scheduler, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ciriculum learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:8fvo2sbo) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▆▅▅▅▅▄▅▃▃▂▂▁▂▁▁</td></tr><tr><td>validation_loss</td><td>█▅▃▂▅▃▃▂▂▁▁▁▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.02845</td></tr><tr><td>validation_loss</td><td>0.04438</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">distilbert-base-uncased</strong> at: <a href='https://wandb.ai/marslab/DaTu_prediction/runs/8fvo2sbo' target=\"_blank\">https://wandb.ai/marslab/DaTu_prediction/runs/8fvo2sbo</a><br/> View project at: <a href='https://wandb.ai/marslab/DaTu_prediction' target=\"_blank\">https://wandb.ai/marslab/DaTu_prediction</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240404_172410-8fvo2sbo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:8fvo2sbo). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/local-scratch/localhome/pagand/projects/DaTu/ML/logda/wandb/run-20240404_172531-qv86yqde</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/marslab/DaTu_prediction/runs/qv86yqde' target=\"_blank\">distilbert-Ciriculum</a></strong> to <a href='https://wandb.ai/marslab/DaTu_prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/marslab/DaTu_prediction' target=\"_blank\">https://wandb.ai/marslab/DaTu_prediction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/marslab/DaTu_prediction/runs/qv86yqde' target=\"_blank\">https://wandb.ai/marslab/DaTu_prediction/runs/qv86yqde</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/marslab/DaTu_prediction/runs/qv86yqde?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7ff2e04dda60>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"DaTu_prediction\", entity=\"marslab\", name = \"distilbert-Ciriculum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CurriculumDaTuDatasett(Dataset):\n",
    "    def __init__(self, sequences, scores, tokenizer, max_length=512):\n",
    "        self.sequences = sequences\n",
    "        self.scores = scores\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "        # Compute complexity of each sequence (e.g., length of the sequence)\n",
    "        self.complexity = [len(seq) for seq in sequences]\n",
    "\n",
    "        # Sort the dataset by complexity\n",
    "        self._sort_by_complexity()\n",
    "\n",
    "    def _sort_by_complexity(self):\n",
    "        # Sort sequences, problem_ids, grades, and complexity based on complexity\n",
    "        combined = sorted(zip(self.sequences, self.scores, self.complexity), key=lambda x: x[2])\n",
    "        self.sequences, self.scores, self.complexity = zip(*combined)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        score = self.scores[idx]\n",
    "\n",
    "        # Tokenize the sequence\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            sequence,\n",
    "            add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "            max_length=self.max_length,  # Max length to truncate/pad\n",
    "            padding='max_length',  # Pad to max_length\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'  # Return PyTorch tensors\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'],\n",
    "            'attention_mask': inputs['attention_mask'],\n",
    "            'labels': torch.tensor(score, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset and dataloader\n",
    "dataset = CurriculumDaTuDatasett(sequences,  scores, tokenizer)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=None)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False, collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localhome/pagand/projects/DaTu/ML/.venv/lib/python3.8/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "epochs = 16\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16 | Train Loss: 0.047 | Validation Loss: 0.038\n",
      "Epoch 2/16 | Train Loss: 0.033 | Validation Loss: 0.037\n",
      "Epoch 3/16 | Train Loss: 0.035 | Validation Loss: 0.043\n",
      "Epoch 4/16 | Train Loss: 0.030 | Validation Loss: 0.045\n",
      "Epoch 5/16 | Train Loss: 0.030 | Validation Loss: 0.043\n",
      "Epoch 6/16 | Train Loss: 0.027 | Validation Loss: 0.046\n",
      "Epoch 7/16 | Train Loss: 0.025 | Validation Loss: 0.056\n",
      "Epoch 8/16 | Train Loss: 0.025 | Validation Loss: 0.045\n",
      "Epoch 9/16 | Train Loss: 0.024 | Validation Loss: 0.053\n",
      "Epoch 10/16 | Train Loss: 0.022 | Validation Loss: 0.046\n",
      "Epoch 11/16 | Train Loss: 0.020 | Validation Loss: 0.054\n",
      "Epoch 12/16 | Train Loss: 0.021 | Validation Loss: 0.046\n",
      "Epoch 13/16 | Train Loss: 0.025 | Validation Loss: 0.048\n",
      "Epoch 14/16 | Train Loss: 0.021 | Validation Loss: 0.046\n",
      "Epoch 15/16 | Train Loss: 0.019 | Validation Loss: 0.050\n",
      "Epoch 16/16 | Train Loss: 0.021 | Validation Loss: 0.049\n"
     ]
    }
   ],
   "source": [
    "train_val_loop(model, train_dataloader, val_dataloader, optimizer, scheduler, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:qv86yqde) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▄▅▄▄▃▂▃▂▂▁▂▃▂▁▁</td></tr><tr><td>validation_loss</td><td>▁▁▃▄▃▄█▄▇▄▇▄▅▄▆▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.02079</td></tr><tr><td>validation_loss</td><td>0.04859</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">distilbert-Ciriculum</strong> at: <a href='https://wandb.ai/marslab/DaTu_prediction/runs/qv86yqde' target=\"_blank\">https://wandb.ai/marslab/DaTu_prediction/runs/qv86yqde</a><br/> View project at: <a href='https://wandb.ai/marslab/DaTu_prediction' target=\"_blank\">https://wandb.ai/marslab/DaTu_prediction</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240404_172531-qv86yqde/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:qv86yqde). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/local-scratch/localhome/pagand/projects/DaTu/ML/logda/wandb/run-20240404_172652-p5pobkgg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/marslab/DaTu_prediction/runs/p5pobkgg' target=\"_blank\">lora-Ciriculum-distilbert</a></strong> to <a href='https://wandb.ai/marslab/DaTu_prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/marslab/DaTu_prediction' target=\"_blank\">https://wandb.ai/marslab/DaTu_prediction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/marslab/DaTu_prediction/runs/p5pobkgg' target=\"_blank\">https://wandb.ai/marslab/DaTu_prediction/runs/p5pobkgg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/marslab/DaTu_prediction/runs/p5pobkgg?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7ff2e04cdca0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"DaTu_prediction\", entity=\"marslab\", name = \"lora-Ciriculum-distilbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.TOKEN_CLS, \n",
    "    inference_mode=False, \n",
    "    r=8, \n",
    "    lora_alpha=8, \n",
    "    lora_dropout=0.1, \n",
    "    target_modules=\"all-linear\",\n",
    "    bias=\"all\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,324,809 || all params: 68,258,322 || trainable%: 1.9408754290795487\n"
     ]
    }
   ],
   "source": [
    "model_peft = get_peft_model(model, peft_config)\n",
    "model_peft.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localhome/pagand/projects/DaTu/ML/.venv/lib/python3.8/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "epochs = 16\n",
    "optimizer = AdamW(model_peft.parameters(), lr=5e-5)\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16 | Train Loss: 0.019 | Validation Loss: 0.050\n",
      "Epoch 2/16 | Train Loss: 0.021 | Validation Loss: 0.048\n",
      "Epoch 3/16 | Train Loss: 0.019 | Validation Loss: 0.047\n",
      "Epoch 4/16 | Train Loss: 0.020 | Validation Loss: 0.047\n",
      "Epoch 5/16 | Train Loss: 0.018 | Validation Loss: 0.049\n",
      "Epoch 6/16 | Train Loss: 0.021 | Validation Loss: 0.048\n",
      "Epoch 7/16 | Train Loss: 0.022 | Validation Loss: 0.049\n",
      "Epoch 8/16 | Train Loss: 0.019 | Validation Loss: 0.048\n",
      "Epoch 9/16 | Train Loss: 0.020 | Validation Loss: 0.049\n",
      "Epoch 10/16 | Train Loss: 0.020 | Validation Loss: 0.047\n",
      "Epoch 11/16 | Train Loss: 0.020 | Validation Loss: 0.048\n",
      "Epoch 12/16 | Train Loss: 0.019 | Validation Loss: 0.048\n",
      "Epoch 13/16 | Train Loss: 0.019 | Validation Loss: 0.048\n",
      "Epoch 14/16 | Train Loss: 0.020 | Validation Loss: 0.048\n",
      "Epoch 15/16 | Train Loss: 0.019 | Validation Loss: 0.048\n",
      "Epoch 16/16 | Train Loss: 0.018 | Validation Loss: 0.048\n"
     ]
    }
   ],
   "source": [
    "train_val_loop(model, train_dataloader, val_dataloader, optimizer, scheduler, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:cgoxp15w) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▂▃▂▃▂▄▂▃▂▃▂▃▃▁▂</td></tr><tr><td>validation_loss</td><td>█▄▃▃▂▁▂▂▂▁▁▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.06102</td></tr><tr><td>validation_loss</td><td>0.06525</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">augment-lora-Ciriculum-distilbert</strong> at: <a href='https://wandb.ai/marslab/DaTu_prediction/runs/cgoxp15w' target=\"_blank\">https://wandb.ai/marslab/DaTu_prediction/runs/cgoxp15w</a><br/> View project at: <a href='https://wandb.ai/marslab/DaTu_prediction' target=\"_blank\">https://wandb.ai/marslab/DaTu_prediction</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240404_172802-cgoxp15w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:cgoxp15w). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/local-scratch/localhome/pagand/projects/DaTu/ML/logda/wandb/run-20240404_173113-lmyqqau1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/marslab/DaTu_prediction/runs/lmyqqau1' target=\"_blank\">augment-lora-Ciriculum-distilbert</a></strong> to <a href='https://wandb.ai/marslab/DaTu_prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/marslab/DaTu_prediction' target=\"_blank\">https://wandb.ai/marslab/DaTu_prediction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/marslab/DaTu_prediction/runs/lmyqqau1' target=\"_blank\">https://wandb.ai/marslab/DaTu_prediction/runs/lmyqqau1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/marslab/DaTu_prediction/runs/lmyqqau1?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7ff2e01deb50>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"DaTu_prediction\", entity=\"marslab\", name = \"augment-lora-Ciriculum-distilbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def augment_sequence(sequences, max_changes, action_prob , time_prob):\n",
    "    all_sequences = []\n",
    "    for sequence in sequences:\n",
    "        all_sequences.append(sequence)\n",
    "       \n",
    "\n",
    "        augmented_sequence = []\n",
    "        number_of_changes = 0\n",
    "        i = 0\n",
    "\n",
    "        while i <len(sequence):\n",
    "\n",
    "            if number_of_changes>=max_changes:\n",
    "                augmented_sequence.extend(sequence[i:])\n",
    "                all_sequences.append(augmented_sequence)\n",
    "                augmented_sequence = sequence[:i]\n",
    "            \n",
    "            token = sequence[i]\n",
    "            if token.startswith('Q'): # dont change the problem id\n",
    "                augmented_sequence.append(token)\n",
    "                i+=1\n",
    "                continue\n",
    "            elif token.startswith('T'): # vary time intervals\n",
    "                # Extract the time value and apply variance\n",
    "                # 'T0', 'T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7', 'T8', 'TMAX',\n",
    "                if random.random() < time_prob:\n",
    "                    number_of_changes += 1\n",
    "                    time_val = int(token[1:]) if token != 'TMAX' else 8\n",
    "                    # choose a random time interval with normal distribution mean = time_val, std = time_prob\n",
    "                    time_val = max(0, min(8, int(np.random.normal(time_val, time_prob))))\n",
    "                    augmented_sequence.append('T' + str(time_val))\n",
    "                else:\n",
    "                    augmented_sequence.append(token)\n",
    "            else: # 'UA','FA','PA','FH', 'UH', 'RH','FE', 'UE','RF', 'RC', 'B', 'C','M', 'S',\n",
    "            # Randomly decide to repeat or skip an action\n",
    "                action = token\n",
    "                p = random.random()\n",
    "                number_of_changes += 1\n",
    "                if p < action_prob:\n",
    "                    # Repeat action\n",
    "                    # randomply select a time interval from T0, T1, T2\n",
    "                    augmented_sequence.extend([action, 'T' + str(random.randint(0, 2)), action])\n",
    "                elif p < 2 * action_prob:\n",
    "                    # Skip action\n",
    "                    i+=2 # skip the time\n",
    "                    continue\n",
    "                elif p < 2.5 * action_prob:\n",
    "                    # Insert a random action\n",
    "                    action_list = ['UA','FA','PA','FH', 'UH', 'RH','FE', 'UE','RF', 'RC', 'B', 'C','M', 'S']\n",
    "                    augmented_sequence.extend([random.choice(action_list), 'T' + str(random.randint(0, 2)), action])\n",
    "                else:\n",
    "                    augmented_sequence.append(action)\n",
    "                    number_of_changes -= 1\n",
    "            i+=1\n",
    "\n",
    "        all_sequences.append(augmented_sequence)\n",
    "    return all_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7554 254\n"
     ]
    }
   ],
   "source": [
    "augmented_sequences = augment_sequence(sequences, max_changes=10, action_prob = 0.005, time_prob=0.03)\n",
    "print(len(augmented_sequences), len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset and dataloader\n",
    "dataset = CurriculumDaTuDatasett(augmented_sequences,  scores, tokenizer)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, _ = random_split(dataset, [train_size, val_size])  # keep the validation the same\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=None)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False, collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localhome/pagand/projects/DaTu/ML/.venv/lib/python3.8/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "epochs = 16\n",
    "optimizer = AdamW(model_peft.parameters(), lr=5e-5)\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16 | Train Loss: 0.063 | Validation Loss: 0.041\n",
      "Epoch 2/16 | Train Loss: 0.065 | Validation Loss: 0.040\n",
      "Epoch 3/16 | Train Loss: 0.065 | Validation Loss: 0.041\n",
      "Epoch 4/16 | Train Loss: 0.065 | Validation Loss: 0.042\n",
      "Epoch 5/16 | Train Loss: 0.063 | Validation Loss: 0.041\n",
      "Epoch 6/16 | Train Loss: 0.062 | Validation Loss: 0.040\n",
      "Epoch 7/16 | Train Loss: 0.062 | Validation Loss: 0.042\n",
      "Epoch 8/16 | Train Loss: 0.067 | Validation Loss: 0.042\n",
      "Epoch 9/16 | Train Loss: 0.065 | Validation Loss: 0.042\n",
      "Epoch 10/16 | Train Loss: 0.064 | Validation Loss: 0.041\n",
      "Epoch 11/16 | Train Loss: 0.065 | Validation Loss: 0.041\n",
      "Epoch 12/16 | Train Loss: 0.063 | Validation Loss: 0.041\n",
      "Epoch 13/16 | Train Loss: 0.063 | Validation Loss: 0.042\n",
      "Epoch 14/16 | Train Loss: 0.065 | Validation Loss: 0.042\n",
      "Epoch 15/16 | Train Loss: 0.065 | Validation Loss: 0.042\n",
      "Epoch 16/16 | Train Loss: 0.065 | Validation Loss: 0.042\n"
     ]
    }
   ],
   "source": [
    "train_val_loop(model, train_dataloader, val_dataloader, optimizer, scheduler, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make sure the validation is not fixed unlike the train that is augmented"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
